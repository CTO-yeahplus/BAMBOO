// app/hooks/useSoundEngine.ts
import { useState, useEffect, useRef, useCallback } from 'react';
import { CallStatus } from '../types'; // types.tsì— CallStatusê°€ ì •ì˜ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.

// [Modified] ì¸ìì— mouseXì™€ callStatus ì¶”ê°€
export function useSoundEngine(
    selectedAmbience: string | null, 
    bgVolume: number, 
    mouseX: any, // MotionValue (Framer Motion)
    callStatus: CallStatus // ëŒ€í™” ìƒíƒœ
) {
  const audioRefs = useRef<Record<string, HTMLAudioElement>>({});
  const audioCtxRef = useRef<AudioContext | null>(null);
  
  // [New] Web Audio API Nodes ì €ì¥ì†Œ
  const sourceNodesRef = useRef<Record<string, MediaElementAudioSourceNode>>({});
  const pannerNodesRef = useRef<Record<string, StereoPannerNode>>({});
  const gainNodesRef = useRef<Record<string, GainNode>>({});

  // Mixer State
  const [isMixerMode, setIsMixerMode] = useState(false);
  const [mixerVolumes, setMixerVolumes] = useState({
      forest: 0.5,
      rain: 0,
      wind: 0,
      ember: 0
  });

  // 1. Audio Context & Nodes ì´ˆê¸°í™” (User Interaction í›„ í•œ ë²ˆë§Œ ì‹¤í–‰)
  const initAudioNodes = useCallback(() => {
      if (!audioCtxRef.current) {
          const AudioContextClass = window.AudioContext || (window as any).webkitAudioContext;
          audioCtxRef.current = new AudioContextClass();
      }
      const ctx = audioCtxRef.current;

      // ê° ì˜¤ë””ì˜¤ ì—˜ë¦¬ë¨¼íŠ¸ë¥¼ Web Audio API ê·¸ë˜í”„ì— ì—°ê²°
      Object.keys(audioRefs.current).forEach(key => {
          const audioEl = audioRefs.current[key];
          // ì´ë¯¸ ì—°ê²°ëœ ë…¸ë“œê°€ ì—†ê³ , ì˜¤ë””ì˜¤ ì—˜ë¦¬ë¨¼íŠ¸ê°€ ì¡´ì¬í•  ë•Œë§Œ ì—°ê²°
          if (audioEl && !sourceNodesRef.current[key]) {
              try {
                  // [Graph] Source -> Gain -> Panner -> Destination
                  const source = ctx.createMediaElementSource(audioEl);
                  const gain = ctx.createGain();
                  const panner = ctx.createStereoPanner();

                  source.connect(gain);
                  gain.connect(panner);
                  panner.connect(ctx.destination);

                  // ë ˆí¼ëŸ°ìŠ¤ ì €ì¥
                  sourceNodesRef.current[key] = source;
                  gainNodesRef.current[key] = gain;
                  pannerNodesRef.current[key] = panner;
                  
                  console.log(`ğŸ”Œ Audio Node Connected: ${key}`);
              } catch (e) {
                  console.warn(`Audio Node Connection Warning (${key}):`, e);
              }
          }
      });
  }, []);

  // 2. [Sonic Reality] Spatial Audio (Pan Control)
  useEffect(() => {
      if (!audioCtxRef.current || !mouseX) return;
      
      // mouseX.get()ì€ -1(ì™¼ìª½) ~ 1(ì˜¤ë¥¸ìª½) ì‚¬ì´ì˜ ê°’
      // ë„ˆë¬´ ê·¹ë‹¨ì ì¸ íŒ¨ë‹ì„ ë°©ì§€í•˜ê¸° ìœ„í•´ 0.8 ê³„ìˆ˜ ì ìš©
      const updatePan = () => {
          const currentPan = mouseX.get() * 0.8; 
          
          Object.values(pannerNodesRef.current).forEach(panner => {
              // ë¶€ë“œëŸ¬ìš´ ì „í™˜ (0.1ì´ˆ ë”œë ˆì´)
              panner.pan.setTargetAtTime(currentPan, audioCtxRef.current!.currentTime, 0.1);
          });
      };

      // MotionValue êµ¬ë…
      const unsubscribe = mouseX.on("change", updatePan);
      return () => unsubscribe();
  }, [mouseX]);

  // 3. [Sonic Reality] Dynamic Silence (Volume & Ducking Logic)
  useEffect(() => {
      // AudioContextê°€ ì—†ê±°ë‚˜ suspended ìƒíƒœë©´ ë…¸ë“œ ì œì–´ê°€ ì•ˆë  ìˆ˜ ìˆìŒ (ì´ˆê¸°í™” ì „)
      if (!audioCtxRef.current) return;

      // ë”í‚¹(Ducking) ê³„ìˆ˜: ëŒ€í™” ì¤‘ì´ë©´ 30%, ì•„ë‹ˆë©´ 100%
      const isTalking = callStatus === 'speaking' || callStatus === 'listening' || callStatus === 'processing';
      const duckingMultiplier = isTalking ? 0.3 : 1.0;

      // ë¯¹ì„œ í‚¤ ë§¤í•‘
      const keyMap: Record<string, string> = { 
          'forest': 'clear', 'rain': 'rain', 'wind': 'snow', 'ember': 'ember' 
      };

      // ëª¨ë“  íŠ¸ë™ ìˆœíšŒí•˜ë©° ë³¼ë¥¨ ì¡°ì ˆ
      Object.keys(audioRefs.current).forEach(key => {
          const gainNode = gainNodesRef.current[key];
          const audioEl = audioRefs.current[key];
          
          if (!gainNode || !audioEl) return;

          let targetVol = 0;

          if (isMixerMode) {
              // ë¯¹ì„œ ëª¨ë“œ
              const mixerKey = Object.keys(keyMap).find(k => keyMap[k] === key);
              if (mixerKey) {
                  targetVol = (mixerVolumes as any)[mixerKey] * bgVolume;
              }
          } else {
              // ì¼ë°˜ ëª¨ë“œ (ì„ íƒëœ ì•°ë¹„ì–¸ìŠ¤ë§Œ ì¬ìƒ)
              targetVol = (key === selectedAmbience) ? bgVolume : 0;
          }

          // ìµœì¢… ë³¼ë¥¨ = ëª©í‘œ ë³¼ë¥¨ * ë”í‚¹ ê³„ìˆ˜
          const finalVol = targetVol * duckingMultiplier;
          
          // Gain Nodeë¥¼ í†µí•œ ë¶€ë“œëŸ¬ìš´ ë³¼ë¥¨ ì „í™˜ (Fade)
          try {
              gainNode.gain.setTargetAtTime(finalVol, audioCtxRef.current!.currentTime, 0.5);
          } catch(e) { /* Ignore context error */ }

          // ì˜¤ë””ì˜¤ ì—˜ë¦¬ë¨¼íŠ¸ ì¬ìƒ/ì¼ì‹œì •ì§€ ê´€ë¦¬
          if (finalVol > 0.01) {
              if (audioEl.paused) {
                  audioEl.play().catch(() => {});
              }
          } else {
              // ì™„ì „íˆ êº¼ì§ˆ ë•Œë§Œ pause (ì•½ê°„ì˜ ì—¬ìœ  ì‹œê°„ í›„)
              if (!audioEl.paused && finalVol === 0) {
                  setTimeout(() => {
                      // ë¹„ë™ê¸° ë”œë ˆì´ í›„ ë³¼ë¥¨ì´ ì—¬ì „íˆ 0ì´ë©´ ì •ì§€
                      if (gainNode.gain.value < 0.01) audioEl.pause();
                  }, 1000);
              }
          }
      });

  }, [callStatus, bgVolume, selectedAmbience, isMixerMode, mixerVolumes]);

  // [New] Mixer Logic Controller
  useEffect(() => {
      // 1. ë¯¹ì„œ ëª¨ë“œê°€ ì¼œì ¸ìˆì„ ë•Œ
      if (isMixerMode) {
        const existingKeys = Object.keys(audioRefs.current);
        console.log("ğŸ¹ [Debug] Registered Audio Keys:", existingKeys);
        // [Key Logic] ë¯¹ì„œì˜ ì´ë¦„(Key)ê³¼ ì‹¤ì œ ì˜¤ë””ì˜¤ íŒŒì¼ì˜ ì´ë¦„(Key)ì„ ì—°ê²°í•´ì£¼ëŠ” ì§€ë„
        const keyMap: Record<string, string> = {
          'forest': 'clear', // ë¯¹ì„œì˜ ForestëŠ” -> ë¬´ì¡°ê±´ 'clear' íƒœê·¸ë¥¼ ì¡°ì‘
          'rain': 'rain',    // ë¯¹ì„œì˜ Rainì€ -> 'rain' íƒœê·¸
          'wind': 'snow',    // ë¯¹ì„œì˜ WindëŠ” -> 'snow' íƒœê·¸ (íŒŒì¼ëª…ì€ winter_windì§€ë§Œ í‚¤ëŠ” snow)
          'ember': 'ember'   // ë¯¹ì„œì˜ FireëŠ” -> 'ember' íƒœê·¸
        };
        // ğŸ” [ìˆ˜ì‚¬ ê¸°ë¡ 1] í˜„ì¬ ì‚¬ìš© ê°€ëŠ¥í•œ ì˜¤ë””ì˜¤ íŠ¸ë™ì´ ë¬´ì—‡ì¸ì§€ í™•ì¸
        console.log("ğŸ§ [Mixer Debug] Available Audio Keys:", Object.keys(audioRefs.current));
        console.log("ğŸšï¸ [Mixer Debug] Master Volume (bgVolume):", bgVolume);

        Object.keys(mixerVolumes).forEach((mixerKey) => {
          const audioKey = keyMap[mixerKey];
              
            // ğŸš¨ [í•µì‹¬ ë³€ê²½] Ref ëŒ€ì‹  IDë¡œ ì§ì ‘ ì°¾ìŠµë‹ˆë‹¤.
            // page.tsxì—ì„œ ë¶€ì—¬í•œ id="spirit-audio-..." ë¥¼ ì°¾ìŠµë‹ˆë‹¤.
            const audio = document.getElementById(`spirit-audio-${audioKey}`) as HTMLAudioElement;
            
            const sliderValue = (mixerVolumes as any)[mixerKey];
            const targetVol = sliderValue * bgVolume;

            if (!audio) {
                console.warn(`âš ï¸ [Mixer] Cannot find element by ID: spirit-audio-${audioKey}`);
                return;
            }

            // ì˜¤ë””ì˜¤ê°€ ë©ˆì¶°ìˆìœ¼ë©´ ì¬ìƒ ì‹œë„
            if (audio.paused && targetVol > 0) {
              console.log(`â–¶ï¸ Starting audio: ${audioKey}`);
              audio.play().catch(e => console.warn(`âš ï¸ Play failed for ${audioKey}:`, e));
            }

            // ë³¼ë¥¨ ì ìš©
            audio.volume = Math.max(0, Math.min(1, targetVol));
            console.log(`âœ… [Applied] ${audioKey} volume set to: ${audio.volume.toFixed(2)} (Target: ${targetVol.toFixed(2)})`);

          if (audio) {
            // ëª©í‘œ ë³¼ë¥¨ ê³„ì‚°: (ìŠ¬ë¼ì´ë” ê°’) * (ë§ˆìŠ¤í„° ë³¼ë¥¨)
            const sliderValue = (mixerVolumes as any)[mixerKey];
            const targetVol = sliderValue * bgVolume;
            
            // ì†Œë¦¬ê°€ êº¼ì ¸ìˆê±°ë‚˜ ë©ˆì¶°ìˆëŠ”ë° ë³¼ë¥¨ì„ ì˜¬ë ¸ë‹¤ë©´ -> ì¬ìƒ ì‹œì‘
            if (audio.paused && targetVol > 0) {
                audio.play().catch(e => console.log("Audio play failed:", e));
            }
            
            // [í•µì‹¬] ì‹¤ì œ ì˜¤ë””ì˜¤ ë³¼ë¥¨ì— ì ìš©
            audio.volume = Math.max(0, Math.min(1, targetVol)); 
            
            // ë””ë²„ê¹…ìš© ë¡œê·¸ (ê°œë°œì ë„êµ¬ ì½˜ì†”ì—ì„œ í™•ì¸ ê°€ëŠ¥)
            console.log(`Mixing: ${audioKey} -> ${audio.volume}`);
          }
        });
      } 
      // 2. ë¯¹ì„œ ëª¨ë“œê°€ êº¼ì¡Œì„ ë•Œ (ê¸°ì¡´ ë‚ ì”¨ ë¡œì§ìœ¼ë¡œ ë³µê·€)
      else {
          Object.keys(audioRefs.current).forEach((key) => {
              const audio = audioRefs.current[key];
              if (audio) {
                  // ì„ íƒëœ ë‚ ì”¨ë§Œ ì¼œê³  ë‚˜ë¨¸ì§€ëŠ” ëˆë‹¤
                  const isTarget = key === selectedAmbience;
                  // fadeToVolume í•¨ìˆ˜ê°€ ìˆë‹¤ë©´ ê·¸ê²ƒì„ í™œìš©, ì•„ë‹ˆë©´ ì§ì ‘ ì œì–´
                  // ì—¬ê¸°ì„œëŠ” ê°„ë‹¨íˆ ì§ì ‘ ì œì–´ ë¡œì§ ì˜ˆì‹œ:
                  if (isTarget) {
                      if (audio.paused) audio.play().catch(() => {});
                      audio.volume = bgVolume; 
                  } else {
                      audio.volume = 0;
                      // ì™„ì „íˆ ë„ì§€ ì•Šê³  0ìœ¼ë¡œ ë‘ì–´ ë¶€ë“œëŸ¬ìš´ ì „í™˜ ëŒ€ê¸°
                  }
              }
          });
      }
  }, [isMixerMode, mixerVolumes, bgVolume, selectedAmbience]);

  useEffect(() => {
    if (typeof window !== 'undefined') {
      const AudioContextClass = window.AudioContext || (window as any).webkitAudioContext;
      audioCtxRef.current = new AudioContextClass();
    }
  }, []);

  const resumeContext = useCallback(() => {
    if (audioCtxRef.current?.state === 'suspended') {
      audioCtxRef.current.resume();
    }
  }, []);

  const initAudio = useCallback(() => {
    resumeContext();
    // [New] ì—¬ê¸°ì„œ ë…¸ë“œ ì´ˆê¸°í™” ì‹¤í–‰
    initAudioNodes();

    const ctx = audioCtxRef.current;
    if (ctx) {
        // Silent Oscillator to wake up AudioContext (iOS workaround)
        const osc = ctx.createOscillator();
        const gain = ctx.createGain();
        gain.gain.value = 0;
        osc.connect(gain);
        gain.connect(ctx.destination);
        osc.start(0);
        osc.stop(0.1);
    }
  }, [resumeContext, initAudioNodes]);

  const playWaterDrop = useCallback(() => {
    resumeContext();
    const ctx = audioCtxRef.current;
    if (!ctx) return;
    const osc = ctx.createOscillator();
    const gain = ctx.createGain();
    osc.connect(gain);
    gain.connect(ctx.destination);
    const now = ctx.currentTime;
    osc.frequency.setValueAtTime(1200, now);
    osc.frequency.exponentialRampToValueAtTime(400, now + 0.15);
    gain.gain.setValueAtTime(0, now);
    gain.gain.linearRampToValueAtTime(0.5, now + 0.01);
    gain.gain.exponentialRampToValueAtTime(0.01, now + 0.3);
    osc.start(now);
    osc.stop(now + 0.3);
  }, [resumeContext]);

  const playWindChime = useCallback(() => {
    resumeContext();
    const ctx = audioCtxRef.current;
    if (!ctx) return;
    const freqs = [2000, 2500, 3200, 4200];
    const detune = Math.random() * 100;
    freqs.forEach((f, i) => {
      const osc = ctx.createOscillator();
      const gain = ctx.createGain();
      const pan = ctx.createStereoPanner();
      osc.connect(gain);
      gain.connect(pan);
      pan.connect(ctx.destination);
      const now = ctx.currentTime;
      osc.type = 'sine';
      osc.frequency.value = f + detune;
      gain.gain.setValueAtTime(0, now);
      gain.gain.linearRampToValueAtTime(0.05, now + 0.05);
      gain.gain.exponentialRampToValueAtTime(0.001, now + 2 + i * 0.5);
      pan.pan.value = (Math.random() * 2 - 1) * 0.5;
      osc.start(now);
      osc.stop(now + 3);
    });
  }, [resumeContext]);

  const playPaperRustle = useCallback(() => {
    resumeContext();
    const ctx = audioCtxRef.current;
    if (!ctx) return;
    const bufferSize = ctx.sampleRate * 0.5;
    const buffer = ctx.createBuffer(1, bufferSize, ctx.sampleRate);
    const data = buffer.getChannelData(0);
    for (let i = 0; i < bufferSize; i++) data[i] = Math.random() * 2 - 1;
    const noise = ctx.createBufferSource();
    noise.buffer = buffer;
    const filter = ctx.createBiquadFilter();
    filter.type = 'lowpass';
    filter.frequency.value = 800;
    const gain = ctx.createGain();
    noise.connect(filter);
    filter.connect(gain);
    gain.connect(ctx.destination);
    const now = ctx.currentTime;
    gain.gain.setValueAtTime(0, now);
    gain.gain.linearRampToValueAtTime(0.2, now + 0.05);
    gain.gain.exponentialRampToValueAtTime(0.01, now + 0.2);
    noise.start(now);
  }, [resumeContext]);

  const playMagicDust = useCallback(() => {
    resumeContext();
    const ctx = audioCtxRef.current;
    if (!ctx) return;
    const count = 5;
    for (let i = 0; i < count; i++) {
      setTimeout(() => {
        const osc = ctx.createOscillator();
        const gain = ctx.createGain();
        osc.type = 'triangle';
        osc.connect(gain);
        gain.connect(ctx.destination);
        const now = ctx.currentTime;
        const notes = [880, 987, 1109, 1318, 1480]; 
        const freq = notes[Math.floor(Math.random() * notes.length)] * 2;
        osc.frequency.value = freq;
        gain.gain.setValueAtTime(0, now);
        gain.gain.linearRampToValueAtTime(0.05, now + 0.01);
        gain.gain.exponentialRampToValueAtTime(0.001, now + 0.3);
        osc.start(now);
        osc.stop(now + 0.3);
      }, i * 50);
    }
  }, [resumeContext]);

  const playIntroBoom = useCallback(() => {
    resumeContext();
    const ctx = audioCtxRef.current;
    if (!ctx) return;

    // Deep Sine
    const osc = ctx.createOscillator();
    const gain = ctx.createGain();
    const filter = ctx.createBiquadFilter();
    osc.connect(filter);
    filter.connect(gain);
    gain.connect(ctx.destination);
    const now = ctx.currentTime;
    osc.frequency.setValueAtTime(150, now);
    osc.frequency.exponentialRampToValueAtTime(40, now + 2.0);
    filter.type = 'lowpass';
    filter.frequency.setValueAtTime(500, now);
    filter.frequency.linearRampToValueAtTime(100, now + 1.5);
    gain.gain.setValueAtTime(0, now);
    gain.gain.linearRampToValueAtTime(1.0, now + 0.1);
    gain.gain.exponentialRampToValueAtTime(0.001, now + 4.0);
    osc.start(now);
    osc.stop(now + 4.0);

    // Rumble Noise
    const bufferSize = ctx.sampleRate * 2.0;
    const buffer = ctx.createBuffer(1, bufferSize, ctx.sampleRate);
    const data = buffer.getChannelData(0);
    for (let i = 0; i < bufferSize; i++) data[i] = (Math.random() * 2 - 1) * 0.5;
    const noise = ctx.createBufferSource();
    noise.buffer = buffer;
    const noiseGain = ctx.createGain();
    const noiseFilter = ctx.createBiquadFilter();
    noiseFilter.type = 'lowpass';
    noiseFilter.frequency.value = 80; 
    noise.connect(noiseFilter);
    noiseFilter.connect(noiseGain);
    noiseGain.connect(ctx.destination);
    noiseGain.gain.setValueAtTime(0.3, now);
    noiseGain.gain.exponentialRampToValueAtTime(0.001, now + 2.0);
    noise.start(now);
  }, [resumeContext]);

  // Preset Functions
  const applyPreset = (preset: 'focus' | 'sleep' | 'morning') => {
    setIsMixerMode(true);
    switch (preset) {
        case 'focus': // ìˆ² ì†Œë¦¬ + ì•½í•œ ë°”ëŒ
            setMixerVolumes({ forest: 0.6, wind: 0.3, rain: 0, ember: 0 });
            break;
        case 'sleep': // ë¹—ì†Œë¦¬ + ì¥ì‘ë¶ˆ
            setMixerVolumes({ forest: 0.1, wind: 0.1, rain: 0.7, ember: 0.4 });
            break;
        case 'morning': // ë§‘ì€ ìˆ² ì†Œë¦¬ë§Œ
            setMixerVolumes({ forest: 0.8, wind: 0.1, rain: 0, ember: 0 });
            break;
    }
  };

  // Binaural State
  const [binauralMode, setBinauralMode] = useState<string>('none');

  // Binaural Logic (ë™ì¼ ìœ ì§€)
  useEffect(() => {
      const beats = ['delta', 'alpha', 'theta'];
      beats.forEach(beat => {
          const audio = document.getElementById(`binaural-${beat}`) as HTMLAudioElement;
          if (!audio) return;

          if (binauralMode === beat) {
              if (audio.paused) audio.play().catch(() => {});
              audio.volume = Math.max(0, Math.min(1, bgVolume * 0.3)); 
          } else {
              if (!audio.paused) {
                  audio.volume = 0;
                  setTimeout(() => audio.pause(), 1000); 
              }
          }
      });
  }, [binauralMode, bgVolume]);

  return { 
      initAudio, 
      playWaterDrop, playWindChime, playPaperRustle, playMagicDust, playIntroBoom,
      isMixerMode, setIsMixerMode,
      mixerVolumes, setMixerVolumes,
      applyPreset, 
      binauralMode, setBinauralMode,
      audioRefs, // Refs ë°˜í™˜ í•„ìˆ˜
   };
}