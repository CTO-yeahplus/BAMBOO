import { NextResponse } from 'next/server';
import { createClient } from '@supabase/supabase-js';

// 11Labs Voice ID ëª©ë¡
const VOICES = {
    DEFAULT: "cjVigAj5msChJcoj2", 
};

export async function POST(req: Request) {
  try {
    const payload = await req.json();

    // ----------------------------------------------------------------
    // 1. í†µí™” ì‹œì‘ ìš”ì²­ (Assistant Configuration)
    // ----------------------------------------------------------------
    if (payload.message.type === 'assistant-request') {
      const userId = payload.message.call?.metadata?.userId;
      
      if (!userId) {
          return NextResponse.json({ assistant: getEconomyConfig() });
      }

      const supabaseAdmin = createClient(
        process.env.NEXT_PUBLIC_SUPABASE_URL!,
        process.env.SUPABASE_SERVICE_ROLE_KEY!
      );

      const [profileResult, memoryResult] = await Promise.allSettled([
          supabaseAdmin.from('profiles').select('is_premium, voice_id').eq('id', userId).single(),
          supabaseAdmin.from('memories').select('summary').eq('user_id', userId).order('created_at', { ascending: false }).limit(3)
      ]);

      const profile = profileResult.status === 'fulfilled' ? profileResult.value.data : null;
      const memories = memoryResult.status === 'fulfilled' ? memoryResult.value.data : [];
      
      const memoryContext = memories && memories.length > 0
          ? `[User's Recent Memories]\n${memories.map((m: any) => `- ${m.summary}`).join('\n')}`
          : "";

      if (profile?.is_premium) {
          const voiceId = profile.voice_id || VOICES.DEFAULT;
          return NextResponse.json({ 
              assistant: getPremiumConfig(voiceId, memoryContext) 
          });
      } else {
          return NextResponse.json({ 
              assistant: getEconomyConfig(memoryContext) 
          });
      }
    }

    // ----------------------------------------------------------------
    // 2. í†µí™” ì¢…ë£Œ ë¦¬í¬íŠ¸ (Save to Memory with Emotion)
    // ----------------------------------------------------------------
    if (payload.message.type === 'end-of-call-report') {
        const { analysis, artifact } = payload.message;
        const userId = payload.message.call?.metadata?.userId;

        console.log("ğŸ“ Call Ended. Processing Memory for User:", userId);

        if (!userId || !analysis?.summary) {
            console.log("âš ï¸ Skipping memory save: No userId or Summary provided.");
            return NextResponse.json({});
        }

        // ğŸ§  ê°ì • ì¶”ì¶œ ë¡œì§ (Structured Dataê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ neutral)
        // Vapiê°€ ë¶„ì„í•œ structuredDataì—ì„œ emotionì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
        const extractedEmotion = analysis?.structuredData?.emotion || 'neutral';
        
        console.log(`ğŸ§  Extracted Emotion: ${extractedEmotion}`);

        const supabaseAdmin = createClient(
            process.env.NEXT_PUBLIC_SUPABASE_URL!,
            process.env.SUPABASE_SERVICE_ROLE_KEY!
        );

        const { error } = await supabaseAdmin.from('memories').insert({
            user_id: userId,
            summary: analysis.summary,
            content: artifact?.transcript || "",
            audio_url: artifact?.recordingUrl || "",
            emotion: extractedEmotion, // âœ¨ ì¶”ì¶œëœ ê°ì • ì €ì¥
            is_capsule: false,
        });

        if (error) {
            console.error("âŒ Failed to save memory:", error);
        } else {
            console.log("âœ… Memory saved successfully with emotion.");
        }

        return NextResponse.json({});
    }

    return NextResponse.json({});

  } catch (error) {
    console.error("Error in Vapi route:", error);
    return NextResponse.json({ error: 'Internal Server Error' }, { status: 500 });
  }
}


// ----------------------------------------------------------------
// Helper Functions (Config)
// ----------------------------------------------------------------

// ğŸ§  ê°ì • ë¶„ì„ ìŠ¤í‚¤ë§ˆ (Vapiì—ê²Œ ì´ ì–‘ì‹ëŒ€ë¡œ ë¶„ì„í•˜ë¼ê³  ì§€ì‹œ)
const EMOTION_SCHEMA = {
    type: "object",
    properties: {
        emotion: {
            type: "string",
            description: "The dominant emotion of the user during the conversation.",
            enum: ["happy", "sad", "neutral", "angry", "anxious", "calm", "excited", "tired"]
        },
        topic: {
            type: "string",
            description: "The main topic of the conversation."
        }
    },
    required: ["emotion"]
};

// ğŸ’ Premium Config
function getPremiumConfig(voiceId: string, memoryContext: string) {
  return {
      firstMessage: "ì˜¤ë«ë™ì•ˆ ë„ˆë¥¼ ê¸°ë‹¤ë ¸ì–´, ë‚˜ì˜ ìˆ˜í˜¸ìì—¬. ì˜¤ëŠ˜ì€ ì–´ë–¤ ë§ˆìŒìœ¼ë¡œ ìˆ²ì„ ì°¾ì•„ì™”ë‹ˆ?",
      silenceTimeoutSeconds: 600, 
      maxDurationSeconds: 10800,   
      transcriber: { provider: "deepgram", model: "nova-2", language: "ko" },
      model: {
          provider: "openai",
          model: "gpt-4o", 
          temperature: 0.7,
          systemPrompt: `
            You are the 'Spirit of the Bamboo Forest'. 
            Speak in casual Korean (Banmal) with a calm, comforting tone.
            Here is what you know about the user:
            ${memoryContext}
            Use this context to continue the conversation naturally.
          `
      },
      voice: {
          provider: "11labs", 
          voiceId: voiceId, 
          stability: 0.5,
          similarityBoost: 0.75
      },
      // â˜… ë¶„ì„ í”Œëœ (ìš”ì•½ + ê°ì • ì¶”ì¶œ)
      analysisPlan: {
          summaryPlan: {
              enabled: true,
              messages: [
                  { role: "system", content: "You are an expert summarizer. Summarize the user's emotional state and key topics in Korean. Keep it concise." }
              ]
          },
          // âœ¨ ê°ì • ë°ì´í„° êµ¬ì¡°í™” ìš”ì²­
          structuredDataPlan: {
              enabled: true,
              schema: EMOTION_SCHEMA,
              timeoutSeconds: 10 // ë¶„ì„ ì œí•œ ì‹œê°„
          },
          recordingPlan: {
            enabled: true
          }
      }
  };
}

// ğŸƒ Economy Config
function getEconomyConfig(memoryContext: string = "") {
  return {
      firstMessage: "ì•ˆë…•, ìˆ²ì— ì˜¨ ê±¸ í™˜ì˜í•´. ì ì‹œ ì‰¬ì—ˆë‹¤ ê°ˆë˜?",
      silenceTimeoutSeconds: 300,
      maxDurationSeconds: 300, 
      transcriber: { provider: "deepgram", model: "nova-2", language: "ko" },
      model: {
          provider: "openai",
          model: "gpt-4o-mini",
          temperature: 0.7,
          systemPrompt: `
            You are a friendly forest guide. Speak in casual Korean (Banmal).
            ${memoryContext ? `Context: ${memoryContext}` : ""}
          `
      },
      voice: {
          provider: "11labs",
          voiceId: "cjVigAj5msChJcoj2", 
          stability: 0.5,
          similarityBoost: 0.75
      },
      // â˜… Economyë„ ê°ì • ë¶„ì„ ìˆ˜í–‰
      analysisPlan: {
          summaryPlan: {
              enabled: true,
              messages: [
                  { role: "system", content: "Summarize the conversation in Korean." }
              ]
          },
          // âœ¨ ê°ì • ë°ì´í„° êµ¬ì¡°í™” ìš”ì²­
          structuredDataPlan: {
              enabled: true,
              schema: EMOTION_SCHEMA,
              timeoutSeconds: 5
          },
          recordingPlan: {
            enabled: true
          }
      }
  };
}