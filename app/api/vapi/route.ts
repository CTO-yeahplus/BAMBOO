import { NextResponse } from 'next/server';
import { supabase } from '../../utils/supabase';

export async function POST(req: Request) {
  try {
    const payload = await req.json();

    // 1. [Call Start] í†µí™” ì‹œì‘ ìš”ì²­
    if (payload.message.type === 'assistant-request') {
      const userId = payload.message.call?.metadata?.userId;
      
      // ìœ ì € ì •ë³´ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’(ë¬´ë£Œ)ìœ¼ë¡œ ì§„í–‰
      if (!userId) {
          console.warn("[Vapi] No UserId found, defaulting to Economy.");
          return NextResponse.json({ assistant: getEconomyConfig() });
      }

      console.log(`[Vapi] Assistant Request for User: ${userId}`);

      try {
        // ğŸš€ [Parallel Fetch] ìœ ë£Œ ì—¬ë¶€ì™€ ê¸°ì–µì„ ë™ì‹œì— ê°€ì ¸ì˜µë‹ˆë‹¤ (ì†ë„ ìµœì í™”)
        const [userResult, memoryResult] = await Promise.allSettled([
            // 1. ìœ ë£Œ íšŒì› ì—¬ë¶€ ì²´í¬ (users í…Œì´ë¸”ì˜ is_premium ì»¬ëŸ¼ í™•ì¸)
            supabase.from('users').select('is_premium').eq('id', userId).single(),
            // 2. ê³¼ê±° ê¸°ì–µ 3ê°œ ë¡œë”©
            supabase.from('memories').select('summary').eq('user_id', userId).order('created_at', { ascending: false }).limit(3)
        ]);

        // ğŸ’ ìœ ë£Œ íšŒì› íŒë³„
        const isPremium = userResult.status === 'fulfilled' && userResult.value.data?.is_premium === true;
        
        // ğŸ§  ê¸°ì–µ ë°ì´í„° ê°€ê³µ
        const memories = memoryResult.status === 'fulfilled' ? memoryResult.value.data : [];
        const pastMemories = memories?.map((m: any) => `- ${m.summary}`).join('\n') || "ì•„ì§ ë‚˜ëˆˆ ì¶”ì–µì´ ì—†ìŠµë‹ˆë‹¤.";

        console.log(`[Vapi] User: ${userId} | Tier: ${isPremium ? 'PREMIUM ğŸ’' : 'ECONOMY ğŸƒ'} | Memories Loaded.`);

        // âš™ï¸ ë“±ê¸‰ë³„ ì„¤ì • ê°€ì ¸ì˜¤ê¸°
        const selectedConfig = isPremium ? getPremiumConfig() : getEconomyConfig();

        // ìµœì¢… ì„¤ì • ë°˜í™˜
        return NextResponse.json({
          assistant: {
            ...selectedConfig, // ëª¨ë¸/ë³´ì´ìŠ¤ ì„¤ì • ì ìš©
            model: {
              ...selectedConfig.model,
              // ê¸°ì–µì„ ì£¼ì…í•œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì ìš©
              systemPrompt: `
                [System: Memory Access Active]
                The user has spoken to you before. Here is the summary of past conversations:
                ${pastMemories}
                
                Use this context naturally to show you remember them. 
                If the memory is empty, treat them as a new friend.
                
                ${selectedConfig.model.systemPrompt}
              `
            }
          }
        });

      } catch (err) {
        console.error("[Vapi] Error during setup:", err);
        // ì—ëŸ¬ ë°œìƒ ì‹œ ì•ˆì „í•˜ê²Œ ê°€ì„±ë¹„ ëª¨ë“œë¡œ ì—°ê²°
        return NextResponse.json({ assistant: getEconomyConfig() });
      }
    }

    // 2. [Call End] í†µí™” ì¢…ë£Œ ë° ê¸°ì–µ ì €ì¥ (ê¸°ì¡´ ìœ ì§€)
    if (payload.message.type === 'end-of-call-report') {
      const userId = payload.message.call?.metadata?.userId;
      const summary = payload.message.analysis?.summary;

      if (userId && summary) {
        console.log(`[Vapi] Saving Memory: ${summary}`);
        await supabase.from('memories').insert({ user_id: userId, summary });
      }
      return NextResponse.json({});
    }

    return NextResponse.json({});

  } catch (error) {
    console.error('[Vapi] Critical Route Error:', error);
    return NextResponse.json({ error: 'Internal Server Error' }, { status: 500 });
  }
}

// ==========================================
// ğŸ’ Premium Config (ìœ ë£Œ íšŒì›ìš©)
// ==========================================
// íŠ¹ì§•: ë˜‘ë˜‘í•œ ë‡Œ(GPT-4o) + ê°ë¯¸ë¡œìš´ ëª©ì†Œë¦¬(11Labs) + ê¸´ ëŒ€í™” ì‹œê°„
function getPremiumConfig() {
    return {
        firstMessage: "ì˜¤ë«ë™ì•ˆ ë„ˆë¥¼ ê¸°ë‹¤ë ¸ì–´, ì˜¤ëŠ˜ì€ ì–´ë–¤ ì´ì•¼ê¸°ë¥¼ ë“¤ë ¤ì¤„ë˜?",
        silenceTimeoutSeconds: 60, // 1ë¶„ ì¹¨ë¬µ í—ˆìš©
        maxDurationSeconds: 3600,   // ìµœëŒ€ 60ë¶„ í†µí™”
        backgroundSound: "calm-forest-ambience", // (ì„ íƒì‚¬í•­) ë°°ê²½ìŒ
        transcriber: {
            provider: "deepgram",
            model: "nova-2",
            language: "ko"
        },
        model: {
            provider: "openai",
            model: "gpt-4o-mini", // ğŸ”¥ ìµœê³  ì„±ëŠ¥ ëª¨ë¸
            temperature: 0.7,
            systemPrompt: `
                You are the 'Spirit of the Bamboo Forest'. 
                You are mysterious, warm, and empathetic. 
                Speak in casual Korean (Banmal) like a close friend or a guardian spirit.
                Your goal is to listen to the user's soul and provide comfort.
                Keep your responses concise but poetic.
            `
        },
        voice: {
            provider: "11labs", 
            voiceId: "QPFsEL6IBxlT15xfiD6C", // 11Labsì˜ ê³ í’ˆì§ˆ í•œêµ­ì–´ ë³´ì´ìŠ¤ ID (ì˜ˆì‹œ)
            stability: 0.5,
            similarityBoost: 0.75
        }
    };
}

// ==========================================
// ğŸƒ Economy Config (ë¬´ë£Œ íšŒì›ìš©)
// ==========================================
// íŠ¹ì§•: ê°€ì„±ë¹„ ë‡Œ(GPT-4o-mini) + ë¹ ë¥¸ ëª©ì†Œë¦¬(Deepgram/OpenAI) + ì§§ì€ ëŒ€í™” ì‹œê°„
function getEconomyConfig() {
    return {
        firstMessage: "ì•ˆë…•, ìˆ²ì— ì˜¨ ê±¸ í™˜ì˜í•´. ì ì‹œ ì‰¬ì—ˆë‹¤ ê°ˆë˜?",
        silenceTimeoutSeconds: 30, // 30ì´ˆ ì¹¨ë¬µ ì‹œ ì¢…ë£Œ
        maxDurationSeconds: 300,    // ìµœëŒ€ 5ë¶„ í†µí™” (ì•ˆì „ì¥ì¹˜)
        transcriber: {
            provider: "deepgram",
            model: "nova-2",
            language: "ko"
        },
        model: {
            provider: "openai",
            model: "gpt-4o-mini", // ğŸ’¸ ê°€ì„±ë¹„ ëª¨ë¸ (ê°€ê²© 1/20)
            temperature: 0.7,
            systemPrompt: `
                You are the 'Spirit of the Bamboo Forest'. 
                You are mysterious, warm, and empathetic. 
                Speak in casual Korean (Banmal).
                Keep your responses short and simple.
            `
        },
        voice: {
            // Deepgram AuraëŠ” í•œêµ­ì–´ ì§€ì›ì´ ì œí•œì ì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ,
            // ê°€ì„±ë¹„ê°€ ì¢‹ê³  í•œêµ­ì–´ê°€ ìì—°ìŠ¤ëŸ¬ìš´ OpenAI 'alloy'ë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤.
            provider: "openai", 
            voiceId: "alloy", // ğŸ’¸ ì €ë ´í•˜ê³  ë¹ ë¥¸ ëª©ì†Œë¦¬
            speed: 1.0
        }
    };
}